{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc3340b1-be1e-40a8-88d5-968fd4dd2126",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e78842-a800-4a36-8aa9-9234ef97908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e904b285-efd4-43b7-957c-6315ddc4906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d2b63b-5785-48cb-a818-79afa39cc58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5425ee5-2090-4e6e-9dea-35332811e85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data) # Two columns so it is a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f7466f0-164a-4291-84af-43e9d757f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd546bd-3c03-40b5-a278-5d7067362fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be447881-2f10-413e-b747-ba9d32a5e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is supervised learning (Classification) as there is a labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6834cbf2-54ac-466d-865a-d06534adfa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding / Label encoder is a method of representing \n",
    "# characters or words by a vector where \n",
    "# only one element is set to one \n",
    "# and all others are zero, based on their position in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9a1d6d3-ca40-46e1-8f70-7c8dbc756b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive -> 1, Negative -> 0\n",
    "data.replace({\"sentiment\": {\"positive\" : 1, \"negative\" : 0}}, inplace=True) \n",
    "# When inplace=True is set, the replacement happens directly on the original DataFrame ('data' variable)\n",
    "# It does not create a new DataFrame and only changes the DataFrame in memory, not the file you loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0a2cdf7-4b37-4d35-aaff-aade75d43b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73f2f033-6a02-4a64-98d3-452b1e6dea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13a8669a-449c-4543-8677-2f16b768de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM -> Long Short Term Memory (Updated version of the RNN)\n",
    "# RNN -> Recurrent Neural Network (Better for smaller datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377aa431-dbbb-47f8-ab71-1d8b91137639",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43445076-2c83-497a-9058-442c53e0f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48d90e3a-147a-41c7-a302-d8ce88c45285",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size = 0.2, random_state=42)\n",
    "#train_data → used to train model\n",
    "# test_data → used to test (evaluate) model on data it has never seen before\n",
    "# 20% of the data goes into the test set and 80% goes into the training set which is generally accepted as a good split\n",
    "# Setting random_state=42 ensures reproducibility → you (and others) always get the same split.\n",
    "# Controls the random shuffling of the data before splitting.\n",
    "# Without it, every time you run the code you might get different train/test splits.\n",
    "# Why 42? It’s just a convention/inside joke from The Hitchhiker’s Guide to the Galaxy (“the answer to everything is 42”). Could use any number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed9519bd-19b4-4cc4-85e5-ed51cef5d995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83beac94-d6ca-4d42-a2fe-c55f5ae9d1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eefd28d0-cc16-49c0-91bd-3c7c90cae1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'i': 1, 'need': 2, 'a': 3, 'job': 4}\n",
      "Sequence: [[1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "## Tokenizer Working Example\n",
    "\n",
    "# Create a fresh tokenizer\n",
    "test_tokenizer = Tokenizer()\n",
    "\n",
    "# Fit tokenizer on a single text\n",
    "test_tokenizer.fit_on_texts([\"I need a job\"])   # NOTE: needs to be inside a list, not just a string\n",
    "\n",
    "# Check the vocabulary\n",
    "print(\"Word Index:\", test_tokenizer.word_index)\n",
    "\n",
    "# Convert the text into numbers (sequence)\n",
    "seq = test_tokenizer.texts_to_sequences([\"I need a job\"])\n",
    "print(\"Sequence:\", seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "431d43fa-e9d5-4795-aa78-1e029e27b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 5000)\n",
    "# Dataset has 50,000 reviews, it may contain tens of thousands of unique words.\n",
    "# By limiting to the most frequent 5,000, we:\n",
    "# Reduce vocabulary size, Reduce memory usage, Make training faster and more stable\n",
    "# Using fewer words = simpler, faster model but maybe less expressive.\n",
    "# Using more words = more detail but heavier computation.\n",
    "tokenizer.fit_on_texts(train_data[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9b6bf72-b5d1-4c7b-ae08-0ae96fb70afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"review\"]), maxlen = 200)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"review\"]), maxlen = 200)\n",
    "# Takes the reviews (text) and converts them into sequences of integers (word indexes).\n",
    "# Each review becomes a list of numbers. \n",
    "# Problem: Different reviews have different lengths (some are short, some very long).\n",
    "# But neural networks need fixed-length input. \n",
    "# Pads or truncates all sequences so they’re the same length.\n",
    "# maxlen=200 → every review will be exactly 200 tokens long. \n",
    "# Larger → more information, but slower training, more memory. \n",
    "# Smaller → faster, but risk losing context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "85ad2de0-9fa0-4519-8326-811ac62d5003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1935,    1, 1200, ...,  205,  351, 3856],\n",
       "       [   3, 1651,  595, ...,   89,  103,    9],\n",
       "       [   0,    0,    0, ...,    2,  710,   62],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1641,    2,  603],\n",
       "       [   0,    0,    0, ...,  245,  103,  125],\n",
       "       [   0,    0,    0, ...,   70,   73, 2062]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "37c3f7b2-0b84-4584-9c0e-73a4f98e7732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  995,  719,  155],\n",
       "       [  12,  162,   59, ...,  380,    7,    7],\n",
       "       [   0,    0,    0, ...,   50, 1088,   96],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  125,  200, 3241],\n",
       "       [   0,    0,    0, ..., 1066,    1, 2305],\n",
       "       [   0,    0,    0, ...,    1,  332,   27]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9bd8600d-1dc2-42b1-be47-8a1d49bda031",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_data[\"sentiment\"]\n",
    "Y_test = test_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "41b2b56d-4605-4238-9fb5-29e4e51e5d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    0\n",
       "30893    0\n",
       "45278    1\n",
       "16398    0\n",
       "13653    0\n",
       "        ..\n",
       "11284    1\n",
       "44732    1\n",
       "38158    0\n",
       "860      1\n",
       "15795    1\n",
       "Name: sentiment, Length: 40000, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1e28f299-3222-4c6a-871f-17e6e42afe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING THE LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e8b1f143-9d5a-4dff-b07e-dfa4721751dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Creates a Sequential model → a stack of layers where data flows step by step.\n",
    "# You add layers one by one in order.\n",
    "model.add(Embedding(input_dim = 5000, output_dim = 128))\n",
    "# Instead of treating words as unrelated IDs, the model learns to place similar words close together in vector space.\n",
    "# Example: “great” and “awesome” → vectors close together. “terrible” → vector far away.\n",
    "# input_dim=5000 → only the top 5k words are included.\n",
    "# output_dim=128 → each word is represented in a 128-dim space.\n",
    "# Output shape: (200, 128) for each review (200 tokens max, each mapped to 128 numbers).\n",
    "model.add(LSTM(128, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "# LSTM (Long Short-Term Memory) is a special RNN that remembers important info and forgets unimportant info as it reads a sequence word by word.\n",
    "# 128 → The number of units (neurons) inside the LSTM. This determines the size of the hidden state (the “memory vector”).\n",
    "# dropout=0.2 → 20% of inputs are randomly dropped out (helps prevent overfitting).\n",
    "# recurrent_dropout=0.2 → 20% dropout on the recurrent connections (the memory links).\n",
    "# Output shape: (128,) → a single 128-dim vector summarizing the whole review.\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "# A fully connected (dense) layer that takes the 128 features from LSTM and outputs one number.\n",
    "# The sigmoid squashes this number into the range [0, 1].\n",
    "# For binary classification (positive/negative sentiment), we want a probability.\n",
    "# Output ≈ 0.95 → confident it’s positive. Output ≈ 0.08 → confident it’s negative.\n",
    "# Dense(1) → one neuron, because we only predict one thing: sentiment.\n",
    "# activation=\"sigmoid\" → converts raw score into probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9a94cbda-a2ad-4f6f-a933-3acb8b12320a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 200))  # None = batch size, 200 = sequence length\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "251feae7-dd4e-4c8d-bb8c-5d87d392dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b3b9c275-f390-440a-a100-1efcb24e9932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 140ms/step - accuracy: 0.7789 - loss: 0.4626 - val_accuracy: 0.8375 - val_loss: 0.3769\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 170ms/step - accuracy: 0.8542 - loss: 0.3489 - val_accuracy: 0.8660 - val_loss: 0.3228\n",
      "Epoch 3/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 170ms/step - accuracy: 0.8773 - loss: 0.3046 - val_accuracy: 0.8618 - val_loss: 0.3297\n",
      "Epoch 4/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 159ms/step - accuracy: 0.8916 - loss: 0.2730 - val_accuracy: 0.8673 - val_loss: 0.3205\n",
      "Epoch 5/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 163ms/step - accuracy: 0.8973 - loss: 0.2572 - val_accuracy: 0.8698 - val_loss: 0.3084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x214c0b04e30>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=64, validation_split = 0.2)\n",
    "# An epoch = 1 full pass through the entire training dataset.\n",
    "# 1 epoch = model sees all 50,000 once. 5 epochs = model sees all 50,000 five times (gets better each time).\n",
    "# Each batch = 64 reviews. Updating weights after each review would be too noisy and too slow.\n",
    "# So the model: \n",
    "# Looks at 64 reviews, Predicts, Calculates average error (loss) over those 64.Updates weights once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f64b1a-d103-4838-96ec-a84fc8285b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile = Set up training rules → optimizer, loss, metrics.\n",
    "# Fit = Train the model → feed data, adjust weights, improve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a1901563-f280-4e3f-8614-f77891f7db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(\"my_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d3636a26-8917-49be-951d-83708e29a7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizer.pkl']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the tokenizer\n",
    "import joblib\n",
    "joblib.dump(tokenizer, \"tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1ef42953-0819-4fdb-8ee5-b7c4dcdb4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8783 - loss: 0.2931\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "# model.evaluate() tests the trained model on new data not used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dea83673-482e-43e6-be7d-dc98d91ee842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29313117265701294\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a95b86e8-9e48-404a-81c8-25c1e2c00a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8783000111579895\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d84a1b41-b240-4408-8e92-299adeea0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "afae065b-7d19-4500-a449-4be590e35943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_system(review):\n",
    "    sequences = tokenizer.texts_to_sequences([review])\n",
    "    # Takes a single review (string) as input.\n",
    "    # Uses the saved tokenizer to convert each word into its integer ID.\n",
    "    # Wrapping [review] in a list makes it compatible with the tokenizer (it expects a list of texts).\n",
    "    padded_sequence = pad_sequences(sequences, maxlen = 200)\n",
    "    # Neural networks expect fixed-length inputs, so we pad (or truncate) sequences.\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    # Feeds the padded review into the trained LSTM model.\n",
    "    # Returns a probability between 0 and 1 because the last layer is sigmoid.\n",
    "    sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "69ba3ec9-ddfb-42d1-877a-a918041a5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictive_system(\"This movie was great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96629a9-b8a4-43bf-baa3-7017ba7e1669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
